{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init():\n    test_df = pd.read_csv(\"../input/titanic/test.csv\")\n    train_df = pd.read_csv(\"../input/titanic/train.csv\")\n    test_df[\"Survived\"]=-8888\n    Main_df=pd.concat((train_df, test_df), axis=0, sort=False)\n    print(\"Checking null values\")\n    print(Main_df.isnull().sum())\n    global title_map\n    title_map={\n    \"mr\": \"Mr\",\"mrs\": \"Mrs\",\"miss\": \"Miss\",\"master\": \"Master\",\"don\": \"Royal\", \"rev\": \"Officer\", \"dr\": \"Officer\",\n    \"mme\": \"Mrs\", \"dona\": \"Royal\", \"jonkheer\" : \"Royal\", \"the countess\": \"Royal\", \"capt\": \"Officer\", \"col\": \"Officer\",\n    \"ms\": \"Mrs\", \"mlle\": \"Miss\", \"major\": \"Officer\", \"lady\" : \"Royal\", \"sir\" : \"Royal\"\n    }\n    return(Main_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_title(x):\n    x=x.split(\",\")[1].split(\".\")[0].strip().lower()\n    return(title_map[x])\n\ndef get_dups(df):\n    df[\"Dup\"]= df.duplicated(\"Name\")\n    uniq_name=df.loc[df[\"Dup\"]==True, \"Name\"].unique()\n    df[\"Is_Dup\"]=np.where(df[\"Name\"].isin(uniq_name), 1, 0)\n    df.drop(\"Dup\", axis=1, inplace=True)\n    return(df)  \n\ndef is_in_group(df):\n    gdf=pd.DataFrame({\"GroupSize\": df.groupby(\"Ticket\")[\"Ticket\"].count()}).reset_index()\n    df=pd.merge(df, gdf, how=\"left\", on=\"Ticket\").set_index(df.index)\n    df[\"NoFamilyGroup\"]=np.where((df[\"SibSp\"]==0) & (df[\"Parch\"]==0) & (df[\"GroupSize\"]>1), 1, 0)\n    df[\"Fare\"].fillna(8.05, inplace=True)\n    df[\"ActualFare\"]=df[\"Fare\"].astype(int)/df[\"GroupSize\"]\n    df[\"IsAlone\"]=np.where(df[\"GroupSize\"] ==1, 1, 0)\n    \n    return(df)\n\ndef adjust_columns(df):\n    columns=[\"AgeState\", \"Title\", \"Sex\", \"Embarked\", \"Deck\", \"FareBin\", \"Pclass\", \"AgeState\"]\n    df=pd.get_dummies(df, columns=columns)\n    df.drop([\"Name\", \"Ticket\", \"Cabin\", \"Fare\", \"Age\", \"ActualFare\", \"FamilySize\", \"NoFamilyGroup\"], axis=1, inplace=True)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"if __name__==\"__main__\":\n    df=init() # Init\n    \n    df[\"Title\"]=df[\"Name\"].map(get_title) #Getting title for each person\n    df=get_dups(df) # Duplicates in name\n    df=is_in_group(df) # Find group based on tickets #.\n    #df[\"Deck\"]= df[\"Cabin\"].apply(lambda x: np.where(pd.notnull(x), str(x)[0].upper(), \"Z\")) # Deck \n    df[\"Deck\"]= np.where(df[\"Cabin\"].isnull(), 0, 1)\n    df[\"FamilySize\"]= df[\"SibSp\"] + df[\"Parch\"] + 1\n    \n    df[\"SmallFamily\"]= np.where((df[\"FamilySize\"] > 1) & (df[\"FamilySize\"] < 5), 1, 0)\n    df[\"MediumFamily\"]= np.where((df[\"FamilySize\"] > 4) & (df[\"FamilySize\"] < 7), 1, 0)\n    df[\"LargeFamily\"]= np.where(df[\"FamilySize\"] > 6, 1, 0)\n\n\n    df[\"Age\"].fillna(df.groupby(['Sex','Title'])[\"Age\"].transform(\"median\"), inplace=True) # Fill age based on median \n    df[\"AgeState\"]= pd.qcut(df[\"Age\"].astype(float), 5, labels=[1, 2, 3,4,5]) # Age buckets\n    df[\"FareBin\"]=  pd.qcut(df[\"ActualFare\"], 3, labels=[1,2,3]) # Fare Buckets\n    df[\"FareBin\"]= np.where(df[\"ActualFare\"]==0,0,df[\"FareBin\"]) # there are passangers with zero fare\n    df[\"IsMother\"]= np.where((df[\"Sex\"]==\"female\") & (df[\"Parch\"] > 0) & (df[\"Title\"] != \"Miss\"), 1, 0) # Mothers\n    \n    # get the value for null embarkment points.\n    Embark_imputer=df.groupby([\"Pclass\", \"Embarked\"]).median()[\"ActualFare\"].reset_index()\n    print(Embark_imputer)\n    print(df.loc[df[\"Embarked\"].isna(), [\"Pclass\", \"ActualFare\"]])\n    df[\"Embarked\"].fillna(\"C\", inplace=True)\n    print(df.isnull().sum()) # Now check null columns \n\n    ##Get the survival rate of key features\n    sex_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"Sex\", \"Survived\"]].groupby(\"Sex\").mean().reset_index()\n    pclass_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"Pclass\", \"Survived\"]].groupby(\"Pclass\").mean().reset_index()\n    embarked_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"Embarked\", \"Survived\"]].groupby(\"Embarked\").mean().reset_index()\n    Age_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"AgeState\", \"Survived\"]].groupby(\"AgeState\").mean().reset_index()\n    Fare_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"FareBin\", \"Survived\"]].groupby(\"FareBin\").mean().reset_index()\n    Deck_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"Deck\", \"Survived\"]].groupby(\"Deck\").mean().reset_index()\n    Group_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"NoFamilyGroup\", \"Survived\"]].groupby(\"NoFamilyGroup\").mean().reset_index()\n    Alone_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"IsAlone\", \"Survived\"]].groupby(\"IsAlone\").mean().reset_index()\n    Mother_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"IsMother\", \"Survived\"]].groupby(\"IsMother\").mean().reset_index()\n    SmallF_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"SmallFamily\", \"Survived\"]].groupby(\"SmallFamily\").mean().reset_index()\n    MediumF_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"MediumFamily\", \"Survived\"]].groupby(\"MediumFamily\").mean().reset_index()\n    LargeF_survival_rate=df.loc[df[\"Survived\"]!=-8888, [\"LargeFamily\", \"Survived\"]].groupby(\"LargeFamily\").mean().reset_index()\n\n\n    \n    fig, (axis1, axis2, axis3, axis4, axis5, axis6, axis7, axis8, axis9, axis10, axis11, axis12) = plt.subplots(1,12, figsize=(15,5))\n    sn.barplot(x='Sex', y='Survived', data=sex_survival_rate, ax=axis1)\n    sn.barplot(x='Pclass', y='Survived', data=pclass_survival_rate, ax=axis2)\n    sn.barplot(x='Embarked', y='Survived', data=embarked_survival_rate, ax=axis3)\n    sn.barplot(x='AgeState', y='Survived', data=Age_survival_rate, ax=axis4)   \n    sn.barplot(x='FareBin', y='Survived', data=Fare_survival_rate, ax=axis5)  \n    sn.barplot(x='Deck', y='Survived', data=Deck_survival_rate, ax=axis6) \n    sn.barplot(x='NoFamilyGroup', y='Survived', data=Group_survival_rate, ax=axis7)    \n    sn.barplot(x='IsAlone', y='Survived', data=Alone_survival_rate, ax=axis8)    \n    sn.barplot(x='IsMother', y='Survived', data=Mother_survival_rate, ax=axis9)    \n    sn.barplot(x='SmallFamily', y='Survived', data=SmallF_survival_rate, ax=axis10)    \n    sn.barplot(x='MediumFamily', y='Survived', data=MediumF_survival_rate, ax=axis11)    \n    sn.barplot(x='LargeFamily', y='Survived', data=LargeF_survival_rate, ax=axis12)    \n\n\n     \n    \n    \n    df=adjust_columns(df) # Feature encoding and selections.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now model\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV,cross_val_score, KFold, learning_curve\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.svm import SVC\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=df.loc[df[\"Survived\"]!=-8888]\ntest=df.loc[df[\"Survived\"]==-8888]\n\nX_train=train.drop(\"Survived\", axis=1).values\nY_train=train[\"Survived\"].values\n\nX_test=test.drop(\"Survived\", axis=1).values\nprint(df.shape, X_train.shape, Y_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's use cross validation to find best model\nkfold=KFold(n_splits=5)\n\nclf=[\"RandomForest\", \"LogisticRegression\", \"SVC\"]\n\nrandom_state = 2\nclassifiers = []\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(SVC(random_state=random_state))\n\nresults, means, std = [], [], []\nfor classifier in classifiers :\n    results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\nfor result in results:\n    means.append(result.mean())\n    std.append(result.std())\n\nresult_DF=pd.DataFrame({\"Classifiers\":clf, \"ResultMeans\":means, \"ResultSTD\":std })\nprint(result_DF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grid_search_param(algo):\n    if algo == \"Logistic\":\n        clf=LogisticRegression()\n        c_space = np.logspace(-5, 8, 15) \n        penalty=[\"l1\", \"l2\"]\n        param_grid = {'C': c_space, 'penalty' : penalty}\n    elif algo==\"RandomForest\":\n        clf=RandomForestClassifier()\n        param_grid = { 'n_estimators': [500],\n                      'max_features': ['auto', 'sqrt', 'log2'],\n                      'max_depth' : [6],\n                      'criterion' :['gini', 'entropy']}  \n\n    return(param_grid, clf)\n\ndef get_best_param(clf, param):\n    grid = GridSearchCV(clf, param, cv = 10) \n    grid.fit(X_train, Y_train) \n    print(\"Tuned   Parameters: {}\".format(grid.best_params_))  \n    print(\"Best score is {}\".format(grid.best_score_)) \n    return(grid)\n\n\ndef run_clf(grid, clf, algo):\n    print(\"Hello\")\n    if algo == \"Logistic\":\n        c_value=grid.best_params_[\"C\"]\n        penalty=grid.best_params_[\"penalty\"]\n        print(\"Best parameter: C is {} and Penalty is {}\".format(c_value, penalty))\n        clf=LogisticRegression(C=c_value, penalty=penalty)\n    \n    elif algo==\"RandomForest\":\n        n_estimators=grid.best_params_[\"n_estimators\"]\n        max_features=grid.best_params_[\"max_features\"]\n        max_depth=grid.best_params_[\"max_depth\"]\n        criterion=grid.best_params_[\"criterion\"]\n        clf=RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, criterion=criterion)\n        \n    clf.fit(X_train, Y_train)\n    print(confusion_matrix(Y_train, clf.predict(X_train)))\n    print(\"{} score is {}\".format(algo, clf.score(X_train,Y_train)))\n    return(clf)\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Running Logistic regression\")\nparam, clf=grid_search_param(\"Logistic\")\n(grid)= get_best_param(clf, param)\nclfLR=run_clf(grid, clf, \"Logistic\")\npred_values=clfLR.predict(X_test)\ntest[\"Survived\"]=pd.Series(pred_values, index=test.index)\ntest[[\"PassengerId\", \"Survived\"]].to_csv(\"LRPrediction.csv\", index=False)\n\nprint(\"Running Random Forest\")\nparam, clf=grid_search_param(\"RandomForest\")\n(grid)= get_best_param(clf, param)\nclfRF=run_clf(grid, clf, \"RandomForest\")  \n\npred_values=clfRF.predict(X_test)\ntest[\"Survived\"]=pd.Series(pred_values, index=test.index)\ntest[[\"PassengerId\", \"Survived\"]].to_csv(\"RFPrediction.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}